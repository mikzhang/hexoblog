---
title: 架构-库存扣减处理
date: 2017-09-22 00:00:00
categories: 架构
tags:
    - 架构
---

库存扣减处理

<!-- more -->

## 基于数据库的库存扣减方案

![1504949094710147.png](1504949094710147.png)

业务复杂、数据量大、并发量大的业务场景下，典型的互联网架构，一般会分为这么几层：

- 调用层，一般是处于端上的browser或者APP
- 站点层，一般是拼装html或者json返回的web-server层
- 服务层，一般是提供RPC调用接口的service层
- 数据层，提供固化数据存储的db

对于库存业务，一般有个库存服务，提供库存的查询、扣减、设置等RPC接口：

![1504949326621170.png](1504949326621170.png)

- 库存查询，stock-service本质上执行的是
select num from stock where sid=$sid
- 库存扣减，stock-service本质上执行的是
update stock set num=num-$reduce where sid=$sid
- 库存设置，stock-service本质上执行的是
update stock set num=$num_new where sid=$sid

用户下单前，一般会对库存进行查询，有足够的存量才允许扣减：

![1504949436407521.png](1504949436407521.png)

如上图所示，通过查询接口，得到库存是5。

用户下单时，接着会对库存进行扣减：

![1504951134210028.png](1504951134210028.png)

如上图所示，购买3单位的商品，通过扣减接口，最终得到库存是2。

希望设计往往有容错机制，例如“重试”，如果通过扣减接口来修改库存，在重试时，可能会得到错误的数据，导致重复扣减：

![1504951225404280.png](1504951225404280.png)

如上图所示，如果数据库层面有重试容错机制，可能导致一次扣减执行两次，最终得到一个负数的错误库存。


重试导致错误的根本原因，是因为“扣减”操作是一个非幂等的操作，不能够重复执行，改成设置操作则不会有这个问题：

![1504951269740234.png](1504951269740234.png)

如上图所示，同样是购买3单位的商品，通过设置库存操作，即使有重试容错机制，也不会得到错误的库存，设置库存是一个幂等操作。

在并发量很大的情况下，还会有其他的问题：

![1504951419394895.png](1504951419394895.png)

如上图所示，两个并发的操作，查询库存，都得到了库存是5。

接下来用户发生了并发的购买动作（秒杀类业务特别容易出现）

![1504951444350576.png](1504951444350576.png)

如上图所示：
- 用户1购买了3个库存，于是库存要设置为2
- 用户2购买了2个库存，于是库存要设置为3
- 这两个设置库存的接口并发执行，库存会先变成2，再变成3，导致数据不一致（实际卖出了5件商品，但库存只扣减了2，最后一次设置库存会覆盖和掩盖前一次并发操作）

其根本原因是，设置操作发生的时候，没有检查库存与查询出来的库存有没有变化，理论上：
- 库存为5时，用户1的库存设置才能成功
- 库存为5时，用户2的库存设置才能成功

实际执行的时候：
- 库存为5，用户1的set stock 2确实应该成功
- 库存变为2了，用户2的set stock 3应该失败掉

升级修改很容易，将库存设置接口，stock-service上执行的：
update stock set num=$y where sid=$sid
升级为：
update stock set num=$num_new where sid=$sid and num=$num_old
这正是大家常说的“Compare And Set”（CAS），是一种常见的降低读写锁冲突，保证数据一致性的方法。

总结
在业务复杂，数据量大，并发量大的情况下，库存扣减容易引发数据的不一致，常见的优化方案有两个：
- 调用“设置库存”接口，能够保证数据的幂等性
- 在实现“设置库存”接口时，需要加上原有库存的比较，才允许设置成功，能解决高并发下库存扣减的一致性问题

ref: 
[架构 库存扣减处理](https://www.w3cschool.cn/architectroad/architectroad-inventory.html)


## 基于缓存的库存扣减方案

场景基于12306购票

通常订票系统要处理生成订单、减扣库存、用户支付这三个基本的阶段。
系统要做的事情是要保证火车票订单不超卖、不少卖，每张售卖的车票都必须支付才有效，还要保证系统承受极高的并发。

这三个阶段的先后顺序如何分配才合理？

### 下单减库存

![snipaste_20191107144327.jpg](snipaste_20191107144327.jpg)

当用户并发请求到达服务端时，首先创建订单，然后扣除库存，等待用户支付。

这种顺序是一般人首先会想到的解决方案，这种情况下也能保证订单不会超卖，因为创建订单之后就会减库存，这是一个原子操作。

会产生一些问题：
- 在极限并发情况下，任何一个内存操作的细节都至关影响性能，尤其像创建订单这种逻辑，一般都需要存储到磁盘数据库的，对数据库的压力是可想而知的。
- 如果用户存在恶意下单的情况，只下单不支付这样库存就会变少，会少卖很多订单，虽然服务端可以限制 IP 和用户的购买订单数量，这也不算是一个好方法。

### 支付减库存

![snipaste_20191107144529.jpg](snipaste_20191107144529.jpg)

如果等待用户支付了订单在减库存，第一感觉就是不会少卖。但是这是并发架构的大忌，因为在极限并发情况下，用户可能会创建很多订单。

当库存减为零的时候很多用户发现抢到的订单支付不了了，这也就是所谓的“超卖”。也不能避免并发操作数据库磁盘 IO。

### 预扣库存

![snipaste_20191107144614.jpg](snipaste_20191107144614.jpg)

从上边两种方案的考虑，我们可以得出结论：只要创建订单，就要频繁操作数据库 IO。

那么有没有一种不需要直接操作数据库 IO 的方案呢，这就是预扣库存。先扣除了库存，保证不超卖，然后异步生成用户订单，这样响应给用户的速度就会快很多；那么怎么保证不少卖呢？用户拿到了订单，不支付怎么办？

我们都知道现在订单都有有效期，比如说用户五分钟内不支付，订单就失效了，订单一旦失效，就会加入新的库存，这也是现在很多网上零售企业保证商品不少卖采用的方案。

订单的生成是异步的，一般都会放到 MQ、Kafka 这样的即时消费队列中处理，订单量比较少的情况下，生成订单非常快，用户几乎不用排队。

ref:
[每秒100万请求，“12306”的架构到底有多牛？](https://mp.weixin.qq.com/s/rFqU9isMESJPDZak5omzKA)


